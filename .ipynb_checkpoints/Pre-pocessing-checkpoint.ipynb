{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = []\n",
    "labels = []\n",
    "\n",
    "# traverse all repositories\n",
    "imagePatches = glob('/Users/HeYilin/Desktop/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "\n",
    "for filename in imagePatches:\n",
    "    file_path.append(filename)\n",
    "\n",
    "len(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels from file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No CSV file in the database\n",
    "# File names indicate labels\n",
    "\n",
    "for i in range(len(file_path)):\n",
    "    if file_path[i][-5] == '0':\n",
    "        labels.append(0)\n",
    "    if file_path[i][-5] == '1':\n",
    "        labels.append(1)\n",
    "        \n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance sample numbers of two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples of IDC(+) and IDC(-)\n",
    "\n",
    "n_0 = 0\n",
    "n_1 = 0\n",
    "\n",
    "for label in labels:\n",
    "    if label == 0:\n",
    "        n_0 += 1\n",
    "    else:\n",
    "        n_1 += 1\n",
    "        \n",
    "print(n_0, n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the sample number of each class\n",
    "# The number of samples used will be 2 * n_per_class\n",
    "\n",
    "n_per_class = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly choose n samples from each class\n",
    "\n",
    "train_file_path = []\n",
    "train_labels = []\n",
    "\n",
    "idx_all = []\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    idx = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == label:\n",
    "            idx.append(i)\n",
    "    idx = random.sample(idx, n_per_class)\n",
    "    idx_all.extend(idx)\n",
    "\n",
    "idx_all = sorted(idx_all)\n",
    "\n",
    "for j in range(len(idx_all)):\n",
    "    train_file_path.append(file_path[idx_all[j]])\n",
    "    train_labels.append(labels[idx_all[j]])\n",
    "    \n",
    "train_labels = np.array(train_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check length of list of file paths\n",
    "\n",
    "len(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check length of list of labels\n",
    "\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.bincount(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png_resize(filepath):\n",
    "    image_string = tf.read_file(filepath) # Read file\n",
    "    image_decoded = tf.image.decode_png(image_string) # Decode images\n",
    "    image_resized = tf.image.resize_images(image_decoded, [75, 75]) # Resize images\n",
    "    return np.array(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a list of pixel information of images after resizing\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(len(train_file_path)):\n",
    "    X.append(png_resize(train_file_path[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_path = \"./Cache/\" # Cache folder\n",
    "fname = 'Resized_Histo.npz' # File name\n",
    "save_path = os.path.join(cache_path, fname) # Create save path for the npz file\n",
    "\n",
    "if not os.path.isdir(cache_path): \n",
    "    os.mkdir(cache_path)\n",
    "    \n",
    "np.savez(save_path, image=X, labels=train_labels) # Save resized images with corresponding labels as npz file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = './Cache/Resized_Histo.npz'\n",
    "data = np.load(npz_path)\n",
    "\n",
    "X = data['image']\n",
    "train_labels = data['labels']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
