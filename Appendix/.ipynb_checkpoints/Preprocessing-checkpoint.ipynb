{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import pydicom\n",
    "import png\n",
    "import csv\n",
    "from os.path import join\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './CSV.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv(csv_path)\n",
    "df_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records labelled as 'BENIGN_WITHOUT_CALLBACK'\n",
    "\n",
    "df = df_0[df_0[\"pathology\"] !='BENIGN_WITHOUT_CALLBACK']\n",
    "df.reset_index(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "\n",
    "labels = []\n",
    "\n",
    "for i in df['pathology']:\n",
    "    if i == 'MALIGNANT':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DICOM to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_png(inputdata, savepath, index_num):\n",
    "    shape = inputdata.shape\n",
    "    image_2d = inputdata.astype(float)\n",
    "    image_2d_scaled = (np.maximum(image_2d,0) / image_2d.max()) * 255.0\n",
    "    image_2d_scaled = np.uint8(image_2d_scaled)\n",
    "    \n",
    "    with open(join(savepath + str(index_num) + '.png'), 'wb') as png_file:\n",
    "        # Save PNG images\n",
    "        w = png.Writer(shape[1], shape[0], greyscale=True)\n",
    "        w.write(png_file, image_2d_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ROI\n",
    "\n",
    "\n",
    "Filter messed ROI and mask images, then convert to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkmask (dicdata):\n",
    "    pd_dic = pd.DataFrame(dicdata)\n",
    "    sum_zero = (pd_dic == 0).sum(axis=1).sum()\n",
    "    sum_size = pd_dic.shape[0]*pd_dic.shape[1]\n",
    "    percentage = sum_zero/sum_size\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcmtopng(input_data, folder_path, save_path):   \n",
    "# input_data: csv file (should be read by pandas, type Dataframe), \n",
    "# folder_path: the path of dicom dataset, \n",
    "# save_path: the path to save png\n",
    "\n",
    "    index_sum = len(input_data) # calculate the length of the dataset\n",
    "    for i in range(index_sum):\n",
    "        mask_path = input_data['ROI mask file path'][i].strip()  # strip the '/n' in the file path of csv file\n",
    "        mass_path = input_data['cropped image file path'][i].strip()\n",
    "        \n",
    "        mask_path = join(folder_path + mask_path) # creat the complete path of file\n",
    "        mass_path = join(folder_path + mass_path)\n",
    "        \n",
    "        data = pydicom.dcmread(mask_path).pixel_array  # read the image information of dicom file\n",
    "        \n",
    "        if checkmask(data) > 0.75:  # check the data and convert it into png, then save to the save path\n",
    "            data = pydicom.dcmread(mass_path).pixel_array\n",
    "            convert_png(data,save_path,i)\n",
    "            \n",
    "        else:\n",
    "            convert_png(data,save_path,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './Mass/'\n",
    "save_path = './PNG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcmtopng(df, folder_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Full mammographs\n",
    "\n",
    "\n",
    "Convert full mammographs into PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcmtopng_full(input_data, folder_path, save_path):   \n",
    "# input_data: csv file (should be read by pandas, type Dataframe) \n",
    "# folder_path: the path of dicom dataset \n",
    "# save_path: the path to save png\n",
    "\n",
    "    index_sum = len(input_data) # calculate the length of the dataset\n",
    "    for i in range(index_sum):\n",
    "        image_path = input_data['image file path'][i].strip()  # strip the '/n' in the file path of csv file\n",
    "        image_path = join(folder_path + image_path) # creat the complete path of file\n",
    "        data = pydicom.dcmread(image_path).pixel_array  # read the image information of dicom file\n",
    "        convert_png(data, save_path, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_2 = './Full/'\n",
    "save_path_2 = './PNG_Full/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcmtopng_full(df, folder_path_2, save_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_size = len(df['cropped image file path'])\n",
    "sample_size = len(df['image file path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_path = []\n",
    "# png_folder = './PNG/'\n",
    "png_folder = './PNG_Full/'\n",
    "ext = '.png'\n",
    "\n",
    "for i in range(sample_size):\n",
    "    png_path.append(join(png_folder+str(i)+ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Xception Model with pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_fmr_images(file_paths):\n",
    "    # Resize png images\n",
    "    def _parse_function(filename):\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_png(image_string)\n",
    "        img=tf.tile(image_decoded,[1,1,3])\n",
    "        image_resized = tf.image.resize_images(img, [299, 299])\n",
    "        return image_resized\n",
    "\n",
    "    file_paths = tf.constant(file_paths)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionBottleneck(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(XceptionBottleneck, self).__init__()\n",
    "        self.xception_layers = Xception(include_top=False, weights='imagenet') \n",
    "        self.pooling_layer = GlobalAveragePooling2D()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        result = self.xception_layers(inputs)\n",
    "        result = self.pooling_layer(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save bottle neck layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottleneck_layers(file_paths, batch_size, device):\n",
    "    \n",
    "    bottle_necks = []\n",
    "    dataset = create_dataset_fmr_images(file_paths).batch(batch_size)\n",
    "    n_samples = len(file_paths)\n",
    "\n",
    "    device = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\n",
    "    \n",
    "    with tf.device(device):\n",
    "        xception_out = XceptionBottleneck()\n",
    "        for batch_num, image in enumerate(dataset):\n",
    "            print('\\rComputing bottle neck layers... batch {} of {}'.format(batch_num+1, n_samples//batch_size), end=\"\")\n",
    "            \n",
    "            # Compute bottle necks layer for image batch convert to numpy and append to bottle_necks\n",
    "            result = xception_out.call(image)\n",
    "            bottle_necks.append(result.numpy())\n",
    "            \n",
    "    return np.vstack(bottle_necks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save bottle necks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\n",
    "bottle_necks = cache_bottleneck_layers(png_path, batch_size=15, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cache_path = './Cache/'\n",
    "\n",
    "fname = 'bottle_neck.npz'\n",
    "save_path = os.path.join(cache_path, fname)\n",
    "\n",
    "if not os.path.isdir(cache_path): \n",
    "    os.mkdir(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(save_path, bottle_necks=bottle_necks, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
